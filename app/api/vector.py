# app/api/vector.py - ìµœì†Œí™” ë²„ì „ (ì •ë§ í•„ìš”í•œ ê²ƒë§Œ)
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func
from typing import Dict, Any
import logging
from datetime import datetime

from app.services.faiss_service import FaissVectorStore
from app.services.recommendation_service import RecommendationService
from app.core.dependencies import get_vector_store, get_recommendation_service
from app.models.database import DBProduct, DBProductEmbedding
from app.core.database import get_async_db


logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/vector", tags=["vector-admin"])


@router.get("/status",
            summary="ë²¡í„° ì €ì¥ì†Œ ìƒíƒœ",
            description="Faiss ë²¡í„° ì €ì¥ì†Œì˜ ê¸°ë³¸ ìƒíƒœ ì •ë³´ (ê´€ë¦¬ììš©)")
async def get_vector_status(
    vector_store: FaissVectorStore = Depends(get_vector_store),
    db: AsyncSession = Depends(get_async_db)
):
    """ë²¡í„° ì €ì¥ì†Œ ê¸°ë³¸ ìƒíƒœ - ê´€ë¦¬ììš©"""
    try:
        # ë²¡í„° ì €ì¥ì†Œ ê¸°ë³¸ ì •ë³´
        store_stats = vector_store.get_store_stats()
        
        # DB ê¸°ë³¸ í†µê³„
        active_products_stmt = select(func.count(DBProduct.id)).where(DBProduct.status == "ACTIVE")
        active_result = await db.execute(active_products_stmt)
        active_product_count = active_result.scalar() or 0
        
        db_embeddings_stmt = select(func.count(DBProductEmbedding.id))
        db_result = await db.execute(db_embeddings_stmt)
        db_embedding_count = db_result.scalar() or 0
        
        return {
            "timestamp": datetime.now().isoformat(),
            "status": "healthy" if store_stats["index_stats"]["total_vectors"] > 0 else "empty",
            "summary": {
                "total_vectors": store_stats["index_stats"]["total_vectors"],
                "active_products": active_product_count,
                "embedding_coverage": f"{(store_stats['index_stats']['total_vectors'] / max(active_product_count, 1) * 100):.1f}%",
                "index_type": store_stats["index_stats"]["index_type"],
                "last_updated": store_stats["index_stats"]["metadata"].get("last_updated", "unknown")
            },
            "health": {
                "vectors_loaded": store_stats["index_stats"]["total_vectors"] > 0,
                "index_ready": store_stats["index_stats"]["status"] == "ready",
                "sufficient_data": store_stats["index_stats"]["total_vectors"] >= 100  # ìµœì†Œ ì„ê³„ê°’
            }
        }
        
    except Exception as e:
        logger.error(f"ë²¡í„° ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.post("/embeddings/batch",
             summary="ë°°ì¹˜ ì„ë² ë”© ìƒì„±", 
             description="í™œì„±í™”ëœ ëª¨ë“  ìƒí’ˆì˜ ì„ë² ë”©ì„ ë°°ì¹˜ë¡œ ìƒì„±í•©ë‹ˆë‹¤ (ê´€ë¦¬ì ì „ìš©)")
async def generate_batch_embeddings(
    background_tasks: BackgroundTasks,
    batch_size: int = 100,
    force_recreate: bool = False,
    db: AsyncSession = Depends(get_async_db)
):
    """ë°°ì¹˜ ì„ë² ë”© ìƒì„± - ì‹œìŠ¤í…œ ì´ˆê¸°í™”ìš©"""
    try:
        # í™œì„±í™”ëœ ìƒí’ˆ ìˆ˜ ì¡°íšŒ
        stmt = select(func.count(DBProduct.id)).where(DBProduct.status == "ACTIVE")
        result = await db.execute(stmt)
        total_products = result.scalar() or 0
        
        if total_products == 0:
            raise HTTPException(status_code=404, detail="ì²˜ë¦¬í•  í™œì„±í™”ëœ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤")
        
        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì²˜ë¦¬
        background_tasks.add_task(
            _process_batch_embeddings,
            force_recreate,
            batch_size
        )
        
        return {
            "status": "started",
            "message": f"ë°°ì¹˜ ì„ë² ë”© ìƒì„±ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
            "details": {
                "total_products": total_products,
                "batch_size": batch_size,
                "estimated_batches": (total_products + batch_size - 1) // batch_size,
                "force_recreate": force_recreate
            },
            "note": "ì²˜ë¦¬ ìƒíƒœëŠ” /vector/statusì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")


async def _process_batch_embeddings(force_recreate: bool, batch_size: int):
    """ë°°ì¹˜ ì„ë² ë”© ì²˜ë¦¬ - ê°„ì†Œí™” ë²„ì „"""
    from app.core.database import AsyncSessionLocal
    from app.core.dependencies import get_recommendation_service
    from sqlalchemy.orm import selectinload
    
    logger.info(f"ğŸ”„ ë°°ì¹˜ ì„ë² ë”© ì²˜ë¦¬ ì‹œì‘: {batch_size}ê°œì”©")
    
    try:
        recommendation_service = await get_recommendation_service()
        processed_count = 0
        
        offset = 0
        while True:
            async with AsyncSessionLocal() as db:
                # ìƒí’ˆ ì¡°íšŒ
                stmt = (
                    select(DBProduct)
                    .options(selectinload(DBProduct.product_options))
                    .where(DBProduct.status == "ACTIVE")
                    .offset(offset)
                    .limit(batch_size)
                )
                
                result = await db.execute(stmt)
                db_products = result.scalars().all()
                
                if not db_products:
                    break
                
                # ì„ë² ë”© ìƒì„± ë° ì €ì¥
                embeddings_data = []
                for db_product in db_products:
                    try:
                        product = await recommendation_service.product_converter.db_to_pydantic(db, db_product)
                        processed_text = recommendation_service.product_tower_service.preprocess_product_text(product)
                        embedding = recommendation_service.embedding_service.encode_text(processed_text)
                        
                        embeddings_data.append({
                            "product_id": int(db_product.id),
                            "embedding": embedding,
                            "metadata": {"created_at": datetime.now().isoformat()}
                        })
                        processed_count += 1
                        
                    except Exception as e:
                        logger.error(f"ìƒí’ˆ {db_product.id} ì„ë² ë”© ì‹¤íŒ¨: {e}")
                        continue
                
                # ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€
                if embeddings_data:
                    await recommendation_service.vector_store.add_embeddings(embeddings_data)
                    logger.info(f"âœ… ë°°ì¹˜ ì™„ë£Œ: {len(embeddings_data)}ê°œ (ì´ {processed_count}ê°œ)")
                
                offset += batch_size
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                import asyncio
                await asyncio.sleep(0.1)
        
        logger.info(f"ğŸ‰ ë°°ì¹˜ ì„ë² ë”© ì™„ë£Œ: {processed_count}ê°œ ìƒí’ˆ ì²˜ë¦¬")
        
    except Exception as e:
        logger.error(f"ë°°ì¹˜ ì„ë² ë”© ì²˜ë¦¬ ì‹¤íŒ¨: {e}")


async def cleanup_vector_service():
    """ë²¡í„° ì„œë¹„ìŠ¤ ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
    try:
        vector_store = await get_vector_store()
        await vector_store.close()
        logger.info("ğŸ”§ ë²¡í„° ì„œë¹„ìŠ¤ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ë²¡í„° ì„œë¹„ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
