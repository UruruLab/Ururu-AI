# app/services/faiss_service.py - 1ë‹¨ê³„ ìˆ˜ì • ì™„ë£Œ ë²„ì „
import faiss
import numpy as np
import json
import logging
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime
import asyncio
from concurrent.futures import ThreadPoolExecutor

from app.core.config import settings

logger = logging.getLogger(__name__)

class FaissIndexManager:
    """Faiss ì¸ë±ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, dimension: int = settings.EMBEDDING_DIMENSION):
        self.dimension = dimension
        self.index = None
        self.product_ids = [] 
        self.metadata = {}
        self.index_type = settings.FAISS_INDEX_TYPE
        self.index_path = Path(settings.FAISS_INDEX_PATH)
        self.index_path.mkdir(parents=True, exist_ok=True)

        thread_pool_size = getattr(settings, 'FAISS_THREAD_POOL_SIZE', 2)
        self.executor = ThreadPoolExecutor(max_workers=thread_pool_size)

        logger.info(f"ğŸ” Faiss ì¸ë±ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” - ì°¨ì›: {dimension}, ì¸ë±ìŠ¤ íƒ€ì…: {self.index_type}")

    def _create_index(self, index_type: str = None) -> faiss.Index:
        """Faiss ì¸ë±ìŠ¤ ìƒì„±"""
        if index_type is None:
            index_type = self.index_type

        logger.debug(f"ğŸ“Š Faiss ì¸ë±ìŠ¤ ìƒì„±: {index_type} (ì°¨ì›: {self.dimension})")

        if index_type == "IndexFlatIP":
            # ë‚´ì  ê¸°ë°˜ ì¸ë±ìŠ¤ - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ìš©
            index = faiss.IndexFlatIP(self.dimension)
        elif index_type == "IndexFlatL2":
            # L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤
            index = faiss.IndexFlatL2(self.dimension)
        elif index_type == "IndexIVFFlat":
            # IVF ì¸ë±ìŠ¤ - ëŒ€ìš©ëŸ‰ ë°ì´í„°ìš©
            quantizer = faiss.IndexFlatL2(self.dimension)
            index = faiss.IndexIVFFlat(quantizer, self.dimension, 100) 
        elif index_type == "IndexHNSW":
            # HNSW ì¸ë±ìŠ¤ - ë¹ ë¥¸ ê·¼ì‚¬ ê²€ìƒ‰
            index = faiss.IndexHNSWFlat(self.dimension, 32) 
        else:
            # ê¸°ë³¸ê°’: Flat IP
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì¸ë±ìŠ¤ íƒ€ì…: {index_type}, IndexFlatIP ì‚¬ìš©")
            index = faiss.IndexFlatIP(self.dimension)
        
        return index
    
    def initialize_index(self, force_recreate: bool = False):
        """Faiss ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
        index_file = self.index_path / f"product_index_{self.index_type}.faiss"
        metadata_file = self.index_path / f"product_metadata_{self.index_type}.json"

        if not force_recreate and index_file.exists() and metadata_file.exists():
            try:
                self._load_index()
                logger.info(f"âœ… ê¸°ì¡´ Faiss ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {len(self.product_ids)}ê°œ ë²¡í„°")
                return
            except Exception as e:
                logger.warning(f"ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}, ì¸ë±ìŠ¤ ì¬ìƒì„± í•„ìš”")

        self.index = self._create_index()
        self.product_ids = []  
        self.metadata = {
            "created_at": datetime.now().isoformat(),
            "index_type": self.index_type,
            "dimension": self.dimension,
            "total_vectors": 0
        }

        logger.info("ğŸ†• ìƒˆ Faiss ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")

    def add_vectors(self, vectors: np.ndarray, product_ids: List[int], batch_metadata: Dict = None):  
        """ë²¡í„°ë“¤ì„ ì¸ë±ìŠ¤ì— ì¶”ê°€"""
        if self.index is None:
            raise ValueError("ì¸ë±ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if len(vectors) != len(product_ids):
            raise ValueError("ë²¡í„°ì™€ ì œí’ˆ IDì˜ ê¸¸ì´ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        if self.index_type == "IndexFlatIP":  
            vectors = self._normalize_vectors(vectors)

        start_idx = len(self.product_ids) 
        self.index.add(vectors.astype(np.float32))
        self.product_ids.extend(product_ids)  

        self.metadata["total_vectors"] = len(self.product_ids) 
        self.metadata["last_updated"] = datetime.now().isoformat()

        if batch_metadata: 
            self.metadata.update(batch_metadata)

        logger.info(f"â• ë²¡í„° ì¶”ê°€ ì™„ë£Œ: {len(vectors)}ê°œ (ì´ {len(self.product_ids)}ê°œ)")

        return start_idx, start_idx + len(vectors)
    
    def search(self, query_vector: np.ndarray, k: int = 10) -> Tuple[List[float], List[int]]:
        """ë²¡í„° ê²€ìƒ‰"""
        if self.index is None or len(self.product_ids) == 0:
            logger.warning("ë¹ˆ ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰ ìš”ì²­")
            return [], []
        
        if self.index_type == "IndexFlatIP":
            query_vector = self._normalize_vectors(query_vector.reshape(1, -1))
        else:
            query_vector = query_vector.reshape(1, -1)

        k = min(k, len(self.product_ids))  
        scores, indices = self.index.search(query_vector.astype(np.float32), k)
        scores = scores[0].tolist()
        product_ids = [self.product_ids[idx] for idx in indices[0] if idx < len(self.product_ids)]  

        logger.debug(f"ğŸ” ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: top-{k}, ìµœê³  ì ìˆ˜: {scores[0]:.4f}")

        return scores, product_ids
    
   
    def search_raw(self, query_vector: np.ndarray, k: int = 10) -> Tuple[np.ndarray, np.ndarray]:
        """ì›ì‹œ ë²¡í„° ê²€ìƒ‰ - Faiss ì ìˆ˜ì™€ ì¸ë±ìŠ¤ë§Œ ë°˜í™˜"""
        if self.index is None or len(self.product_ids) == 0:
            logger.warning("ë¹ˆ ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰ ìš”ì²­")
            return np.array([]), np.array([])

        if self.index_type == "IndexFlatIP":
            query_vector = self._normalize_vectors(query_vector.reshape(1, -1))
        else:
            query_vector = query_vector.reshape(1, -1)

        k = min(k, len(self.product_ids))
        scores, indices = self.index.search(query_vector.astype(np.float32), k)

        logger.debug(f"ğŸ” ì›ì‹œ ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: top-{k}")

        return scores[0], indices[0]
    
    async def search_async(self, query_vector: np.ndarray, k: int = 10) -> Tuple[List[float], List[int]]:
        """ë¹„ë™ê¸° ë²¡í„° ê²€ìƒ‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.executor, self.search, query_vector, k)
    
    async def search_raw_async(self, query_vector: np.ndarray, k: int = 10) -> Tuple[np.ndarray, np.ndarray]:
        """ë¹„ë™ê¸° ì›ì‹œ ë²¡í„° ê²€ìƒ‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.executor, self.search_raw, query_vector, k)
    
    def get_product_ids_by_indices(self, indices: np.ndarray) -> List[int]:
        """ì¸ë±ìŠ¤ë¥¼ ìƒí’ˆ IDë¡œ ë³€í™˜"""
        return [self.product_ids[idx] for idx in indices if idx < len(self.product_ids)]
    
    def _normalize_vectors(self, vectors: np.ndarray) -> np.ndarray:
        """ë²¡í„° ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ìš©)"""
        norms = np.linalg.norm(vectors, axis=1, keepdims=True)
        norms[norms == 0] = 1 
        return vectors / norms
    
    def save_index(self):
        """ì¸ë±ìŠ¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if self.index is None:
            logger.warning("ì €ì¥í•  ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        index_file = self.index_path / f"product_index_{self.index_type}.faiss"
        metadata_file = self.index_path / f"product_metadata_{self.index_type}.json"
        
        try:
            faiss.write_index(self.index, str(index_file))
            
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "metadata": self.metadata,
                    "product_ids": self.product_ids
                }, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"ğŸ’¾ Faiss ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {index_file}")
            
        except Exception as e:
            logger.error(f"ì¸ë±ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def _load_index(self):
        """ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ"""
        index_file = self.index_path / f"product_index_{self.index_type}.faiss"
        metadata_file = self.index_path / f"product_metadata_{self.index_type}.json"
        
        self.index = faiss.read_index(str(index_file))
        
        with open(metadata_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            self.metadata = data["metadata"]
            self.product_ids = data["product_ids"]
        
        logger.debug(f"ğŸ“‚ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {len(self.product_ids)}ê°œ ë²¡í„°")
    
    def remove_vectors(self, product_ids_to_remove: List[int]):
        """íŠ¹ì • ìƒí’ˆë“¤ì˜ ë²¡í„° ì œê±° (ì¬êµ¬ì¶• ë°©ì‹)"""
        if not product_ids_to_remove:
            return
        
        remaining_indices = []
        remaining_product_ids = []
        
        for i, pid in enumerate(self.product_ids):
            if pid not in product_ids_to_remove:
                remaining_indices.append(i)
                remaining_product_ids.append(pid)
        
        if not remaining_indices:
            self.index = self._create_index()
            self.product_ids = []
            logger.info("ğŸ—‘ï¸ ëª¨ë“  ë²¡í„° ì œê±° ì™„ë£Œ")
            return
        
        old_vectors = np.array([self.index.reconstruct(i) for i in remaining_indices])
        
        self.index = self._create_index()
        self.product_ids = []
        self.add_vectors(old_vectors, remaining_product_ids)
        
        logger.info(f"ğŸ—‘ï¸ ë²¡í„° ì œê±° ì™„ë£Œ: {len(product_ids_to_remove)}ê°œ ì œê±°, {len(remaining_product_ids)}ê°œ ìœ ì§€")

    def get_index_stats(self) -> Dict:
        """ì¸ë±ìŠ¤ í†µê³„ ì •ë³´"""
        if self.index is None:
            return {"status": "not_initialized"}
        
        return {
            "status": "ready",
            "index_type": self.index_type,
            "dimension": self.dimension,
            "total_vectors": len(self.product_ids),
            "index_size_mb": self.index.ntotal * self.dimension * 4 / (1024 * 1024),  # float32 ê¸°ì¤€
            "metadata": self.metadata
        }
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=True)
        logger.info("ğŸ”’ Faiss ì¸ë±ìŠ¤ ë§¤ë‹ˆì € ì¢…ë£Œ")
        
    
class FaissVectorStore:
    """Faiss ë²¡í„° ì €ì¥ì†Œ - ìˆ˜ì • ì™„ë£Œ"""
    
    def __init__(self):
        self.index_manager = FaissIndexManager()
        self.index_manager.initialize_index()
        logger.info("ğŸš€ Faiss ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def add_embeddings(self, embeddings_data: List[Dict]) -> bool: 
        """ì„ë² ë”© ë°ì´í„°ë¥¼ ì €ì¥ì†Œì— ì¶”ê°€"""
        try:
            if not embeddings_data:
                logger.warning("ì¶”ê°€í•  ì„ë² ë”© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            vectors = []
            product_ids = []
            
            for data in embeddings_data:
                vectors.append(data["embedding"])
                product_ids.append(data["product_id"])
            
            vectors_array = np.array(vectors)
            
            # ë¹„ë™ê¸°ì ìœ¼ë¡œ ì¶”ê°€
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(
                self.index_manager.executor,
                self.index_manager.add_vectors,
                vectors_array,
                product_ids
            )
            
            # ìë™ ì €ì¥
            await loop.run_in_executor(
                self.index_manager.executor,
                self.index_manager.save_index
            )
            
            logger.info(f"âœ… ì„ë² ë”© ì €ì¥ ì™„ë£Œ: {len(embeddings_data)}ê°œ")
            return True
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    async def search_vectors(self, query_embedding: List[float], k: int = 10) -> Tuple[List[float], List[int]]:
        """ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰ - ì›ì‹œ ì ìˆ˜ì™€ ìƒí’ˆ IDë§Œ ë°˜í™˜"""
        try:
            query_vector = np.array(query_embedding)
            scores, indices = await self.index_manager.search_raw_async(query_vector, k)
            
            # ìƒí’ˆ ID ë³€í™˜
            product_ids = self.index_manager.get_product_ids_by_indices(indices)
            
            logger.debug(f"ğŸ” ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(product_ids)}ê°œ ê²°ê³¼")
            return scores.tolist(), product_ids
            
        except Exception as e:
            logger.error(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return [], []
    
    def get_store_stats(self) -> Dict:  
        """ì €ì¥ì†Œ í†µê³„"""
        return {
            "store_name": "FaissVectorStore",
            "index_stats": self.index_manager.get_index_stats(),
            "settings": {
                "embedding_dimension": settings.EMBEDDING_DIMENSION,
                "index_type": settings.FAISS_INDEX_TYPE,
                "min_similarity_threshold": getattr(settings, 'MIN_SIMILARITY_THRESHOLD', 0.3),
                "max_similarity_threshold": getattr(settings, 'MAX_SIMILARITY_THRESHOLD', 1.0)
            }
        }
    
    async def close(self):
        """ì €ì¥ì†Œ ì¢…ë£Œ"""
        if hasattr(self.index_manager, 'executor'):
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, self.index_manager.close)
        logger.info("ğŸ”’ Faiss ë²¡í„° ì €ì¥ì†Œ ì¢…ë£Œ")